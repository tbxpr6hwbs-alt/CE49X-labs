#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Lab 4: Statistical Analysis - Descriptive Statistics and Probability Distributions
Course: CE49X
Author: Auto-generated by ChatGPT
Python: 3.10+
Dependencies: pandas, numpy, matplotlib, scipy

This script implements the full Lab 4 workflow:
- Descriptive statistics (central tendency, spread, shape, quantiles)
- Probability distributions (discrete & continuous) with engineering scenarios
- Distribution fitting (normal) on concrete strength data
- Probability applications (conditional probability & Bayes' theorem)
- Visualizations (>= 5 PNGs)
- Text report summarizing results

It expects datasets in a root-level `datasets/` folder relative to this file:
    ../datasets/concrete_strength.csv
    ../datasets/structural_loads.csv
    ../datasets/material_properties.csv

Outputs are saved next to this script, under the same folder.
"""

from __future__ import annotations

import argparse
import os
from pathlib import Path
from typing import Dict, Optional, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats


# -------------------------------
# Paths & Utilities
# -------------------------------

def _datasets_root_from_here() -> Path:
    """
    Resolve the datasets root relative to this script's location.
    If the expected path doesn't exist, fall back to environment paths or current working dir.
    """
    here = Path(__file__).resolve().parent
    candidate = (here / ".." / ".." / "datasets").resolve()
    if candidate.exists():
        return candidate

    # Fallbacks
    env = os.environ.get("LAB4_DATASETS")
    if env and Path(env).exists():
        return Path(env)

    # As last resort, try ./datasets relative to cwd
    cwd_candidate = (Path.cwd() / "datasets").resolve()
    if cwd_candidate.exists():
        return cwd_candidate

    # Return candidate anyway (may raise later if missing)
    return candidate


def load_data(file_name: str) -> pd.DataFrame:
    """
    Load dataset from CSV located in the root-level datasets/ folder.
    Example:
        df = load_data('concrete_strength.csv')
    The function automatically navigates from labs/lab4/ to ../datasets/.
    """
    # Absolute path support
    p = Path(file_name)
    if p.exists():
        return pd.read_csv(p)

    # Relative to datasets root
    datasets_root = _datasets_root_from_here()
    csv_path = (datasets_root / file_name).resolve()
    if not csv_path.exists():
        raise FileNotFoundError(f"Could not find: {csv_path}")
    return pd.read_csv(csv_path)


# -------------------------------
# Descriptive Statistics
# -------------------------------

def calculate_descriptive_stats(data: pd.DataFrame, column: str) -> pd.DataFrame:
    """
    Calculate descriptive statistics for the specified column.
    Returns a single-row DataFrame with named metrics.
    """
    s = data[column].dropna()
    mode_vals = s.mode()
    mode_val = mode_vals.iloc[0] if not mode_vals.empty else np.nan

    stats_df = pd.DataFrame({
        "count": [s.count()],
        "mean": [s.mean()],
        "median": [s.median()],
        "mode": [mode_val],
        "std": [s.std(ddof=1)],
        "variance": [s.var(ddof=1)],
        "min": [s.min()],
        "q1": [s.quantile(0.25)],
        "q2_median": [s.quantile(0.50)],
        "q3": [s.quantile(0.75)],
        "max": [s.max()],
        "range": [s.max() - s.min()],
        "iqr": [s.quantile(0.75) - s.quantile(0.25)],
        "skewness": [s.skew()],
        "kurtosis": [s.kurtosis()],
    })
    return stats_df


def plot_distribution(data: pd.DataFrame,
                      column: str,
                      title: str,
                      save_path: Optional[Path] = None,
                      show_sigma_bands: bool = True) -> None:
    """
    Create a histogram + KDE-like smooth curve (via Gaussian KDE) and mark
    mean, median, and mode. Optionally show ±1σ, ±2σ, ±3σ bands.

    Notes for Civil Engineers:
        - Mean and standard deviation describe average strength and variability.
        - Sigma bands indicate probabilities for normal-like data:
          ~68% within ±1σ, ~95% within ±2σ, ~99.7% within ±3σ.
        - Wider spread may imply greater uncertainty in design margins.
    """
    s = data[column].dropna().values
    mu, sigma = np.mean(s), np.std(s, ddof=1)

    fig, ax = plt.subplots(figsize=(8, 5))
    # Histogram
    ax.hist(s, bins="auto", density=True, alpha=0.6, edgecolor="black")

    # Smooth density using gaussian_kde
    try:
        kde = stats.gaussian_kde(s)
        xs = np.linspace(s.min(), s.max(), 400)
        ax.plot(xs, kde(xs), linewidth=2)
    except Exception:
        pass  # In case KDE fails for small or discrete data

    # Markers for mean, median, mode
    median = np.median(s)
    mode_vals = stats.mode(s, keepdims=True)[0]
    mode_val = float(mode_vals[0]) if len(mode_vals) > 0 else np.nan

    for val, label in [(mu, "Mean"), (median, "Median"), (mode_val, "Mode")]:
        ax.axvline(val, linestyle="--", linewidth=1.5, label=f"{label}: {val:.2f}")

    # ± σ bands
    if show_sigma_bands and np.isfinite(mu) and np.isfinite(sigma) and sigma > 0:
        for k in [1, 2, 3]:
            ax.axvspan(mu - k * sigma, mu + k * sigma, alpha=0.08)

    ax.set_title(title)
    ax.set_xlabel(column)
    ax.set_ylabel("Density")
    ax.legend(loc="best")
    ax.grid(True, linestyle=":")

    if save_path:
        fig.tight_layout()
        fig.savefig(save_path, dpi=200)
    plt.close(fig)


# -------------------------------
# Distribution Fitting
# -------------------------------

def fit_distribution(data: pd.DataFrame, column: str,
                     distribution_type: str = "normal") -> Dict[str, float]:
    """
    Fit a probability distribution to the data.
    Currently supports 'normal' only; returns the fitted parameters.
    """
    s = data[column].dropna().values
    if distribution_type.lower() == "normal":
        mu, sigma = stats.norm.fit(s)  # MLE fit
        return {"distribution": "normal", "mu": mu, "sigma": sigma}
    else:
        raise NotImplementedError("Only 'normal' distribution fitting is implemented.")


def plot_distribution_fitting(data: pd.DataFrame,
                              column: str,
                              fitted_params: Dict[str, float],
                              save_path: Optional[Path] = None,
                              synthetic_n: int = 1000) -> None:
    """
    Visualize fitted distribution over histogram and compare to synthetic data.
    """
    s = data[column].dropna().values
    mu = fitted_params.get("mu")
    sigma = fitted_params.get("sigma")

    fig, ax = plt.subplots(figsize=(8, 5))
    ax.hist(s, bins="auto", density=True, alpha=0.6, edgecolor="black", label="Observed")

    # Overlay fitted normal PDF
    xs = np.linspace(s.min(), s.max(), 400)
    pdf = stats.norm.pdf(xs, loc=mu, scale=sigma)
    ax.plot(xs, pdf, linewidth=2, label=f"Fitted Normal μ={mu:.2f}, σ={sigma:.2f}")

    # Synthetic sample overlay (density via KDE)
    synthetic = np.random.normal(loc=mu, scale=sigma, size=synthetic_n)
    try:
        kde_syn = stats.gaussian_kde(synthetic)
        ax.plot(xs, kde_syn(xs), linestyle="--", linewidth=1.5, label="Synthetic KDE")
    except Exception:
        pass

    ax.set_title(f"Distribution Fitting: {column}")
    ax.set_xlabel(column)
    ax.set_ylabel("Density")
    ax.legend(loc="best")
    ax.grid(True, linestyle=":")
    if save_path:
        fig.tight_layout()
        fig.savefig(save_path, dpi=200)
    plt.close(fig)


# -------------------------------
# Probability Calculations
# -------------------------------

def calculate_probability_binomial(n: int, p: float, k: int) -> float:
    """P(X = k) for Binomial(n, p)."""
    return float(stats.binom.pmf(k, n, p))


def calculate_probability_binomial_cdf(n: int, p: float, k: int) -> float:
    """P(X <= k) for Binomial(n, p)."""
    return float(stats.binom.cdf(k, n, p))


def calculate_probability_poisson(lmbda: float, k: int) -> float:
    """P(X = k) for Poisson(λ)."""
    return float(stats.poisson.pmf(k, lmbda))


def calculate_probability_poisson_sf(lmbda: float, k: int) -> float:
    """P(X > k) for Poisson(λ)."""
    return float(stats.poisson.sf(k, lmbda))


def calculate_probability_normal(mean: float, std: float,
                                 x_lower: Optional[float] = None,
                                 x_upper: Optional[float] = None) -> float:
    """
    P(x_lower < X < x_upper) for Normal(mean, std).
    If one bound is None, computes tail probability accordingly.
    """
    dist = stats.norm(loc=mean, scale=std)
    if x_lower is None and x_upper is None:
        return 1.0
    if x_lower is None:
        return float(dist.cdf(x_upper))
    if x_upper is None:
        return float(dist.sf(x_lower))
    return float(dist.cdf(x_upper) - dist.cdf(x_lower))


def calculate_probability_exponential(mean: float, x: float,
                                      tail: str = "le") -> float:
    """
    For Exponential with mean (1/λ) = mean:
        tail='le' -> P(X <= x)
        tail='gt' -> P(X > x)
    """
    lmbda = 1.0 / mean
    dist = stats.expon(scale=1 / lmbda)
    if tail == "le":
        return float(dist.cdf(x))
    elif tail == "gt":
        return float(dist.sf(x))
    else:
        raise ValueError("tail must be 'le' or 'gt'")


def apply_bayes_theorem(prior: float, sensitivity: float, specificity: float) -> Dict[str, float]:
    """
    Apply Bayes' theorem for a diagnostic test.
    Returns posteriors: PPV (P(Damage|+)) and NPV (P(No Damage|-)).
    """
    # True Positive Rate = sensitivity
    # True Negative Rate = specificity
    p_d = prior
    p_not_d = 1 - p_d

    p_pos_given_d = sensitivity
    p_neg_given_not_d = specificity

    p_pos = p_pos_given_d * p_d + (1 - p_neg_given_not_d) * p_not_d
    p_neg = 1 - p_pos

    ppv = (p_pos_given_d * p_d) / p_pos if p_pos > 0 else np.nan
    npv = (p_neg_given_not_d * p_not_d) / p_neg if p_neg > 0 else np.nan

    return {"PPV": float(ppv), "NPV": float(npv), "P(+)": float(p_pos), "P(-)": float(p_neg)}


# -------------------------------
# Comparative Visualization
# -------------------------------

def plot_material_comparison(data: pd.DataFrame,
                             column: str,
                             group_column: str,
                             save_path: Optional[Path] = None) -> None:
    """
    Comparative boxplot across materials (variability, medians).
    Interpretation:
        - Wider boxes/whiskers -> larger variability (design uncertainty).
        - Higher medians -> typical higher strength.
    """
    groups = data[group_column].unique()
    series_list = [data.loc[data[group_column] == g, column].dropna().values for g in groups]

    fig, ax = plt.subplots(figsize=(8, 5))
    ax.boxplot(series_list, labels=groups, showmeans=True)
    ax.set_title(f"{column} by {group_column}")
    ax.set_xlabel(group_column)
    ax.set_ylabel(column)
    ax.grid(True, linestyle=":")
    if save_path:
        fig.tight_layout()
        fig.savefig(save_path, dpi=200)
    plt.close(fig)


# -------------------------------
# Visualization: Probability Distributions & Bayes Tree
# -------------------------------

def plot_probability_distributions(save_path: Optional[Path] = None) -> None:
    """
    Create a multi-panel figure with PMF/PDF and CDF examples for common dists.
    """
    fig, axes = plt.subplots(2, 3, figsize=(12, 7))

    # Bernoulli/ Binomial example (n=20, p=0.2)
    n, p = 20, 0.2
    k = np.arange(0, n + 1)
    pmf = stats.binom.pmf(k, n, p)
    axes[0, 0].stem(k, pmf, use_line_collection=True)
    axes[0, 0].set_title("Binomial(n=20,p=0.2) PMF")
    axes[1, 0].step(k, stats.binom.cdf(k, n, p), where="post")
    axes[1, 0].set_title("Binomial CDF")
    for ax in axes[:, 0]:
        ax.set_xlabel("k"); ax.grid(True, linestyle=":")

    # Poisson example (λ=10)
    lam = 10
    k2 = np.arange(0, 25)
    axes[0, 1].stem(k2, stats.poisson.pmf(k2, lam), use_line_collection=True)
    axes[0, 1].set_title("Poisson(λ=10) PMF")
    axes[1, 1].step(k2, stats.poisson.cdf(k2, lam), where="post")
    axes[1, 1].set_title("Poisson CDF")
    for ax in axes[:, 1]:
        ax.set_xlabel("k"); ax.grid(True, linestyle=":")

    # Continuous: Normal (μ=0, σ=1)
    xs = np.linspace(-4, 4, 400)
    axes[0, 2].plot(xs, stats.norm.pdf(xs))
    axes[0, 2].set_title("Normal(0,1) PDF")
    axes[1, 2].plot(xs, stats.norm.cdf(xs))
    axes[1, 2].set_title("Normal CDF")
    for ax in axes[:, 2]:
        ax.set_xlabel("x"); ax.grid(True, linestyle=":")

    fig.tight_layout()
    if save_path:
        fig.savefig(save_path, dpi=200)
    plt.close(fig)


def plot_bayes_probability_tree(prior: float, sensitivity: float, specificity: float,
                                save_path: Optional[Path] = None) -> None:
    """
    Draw a simple probability tree diagram for the Bayes scenario using Matplotlib.
    """
    results = apply_bayes_theorem(prior, sensitivity, specificity)

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.axis("off")

    # Node positions
    root = (0.05, 0.5)
    damage = (0.35, 0.7)
    no_damage = (0.35, 0.3)
    pos_given_damage = (0.75, 0.8)
    neg_given_damage = (0.75, 0.6)
    pos_given_no = (0.75, 0.4)
    neg_given_no = (0.75, 0.2)

    # Draw lines
    def line(p1, p2):
        ax.plot([p1[0], p2[0]], [p1[1], p2[1]], lw=2, color="black")

    line(root, damage); line(root, no_damage)
    line(damage, pos_given_damage); line(damage, neg_given_damage)
    line(no_damage, pos_given_no); line(no_damage, neg_given_no)

    # Annotate nodes
    ax.text(*root, "Start", ha="left", va="center", fontsize=11)

    ax.text(*damage, f"Damage (P={prior:.2f})", ha="left", va="center", fontsize=11)
    ax.text(*no_damage, f"No Damage (P={1-prior:.2f})", ha="left", va="center", fontsize=11)

    ax.text(*pos_given_damage, f"Test + | D (Sens={sensitivity:.2f})", ha="left", va="center", fontsize=10)
    ax.text(*neg_given_damage, f"Test - | D (1-Sens={1-sensitivity:.2f})", ha="left", va="center", fontsize=10)

    ax.text(*pos_given_no, f"Test + | ¬D (1-Spec={1-specificity:.2f})", ha="left", va="center", fontsize=10)
    ax.text(*neg_given_no, f"Test - | ¬D (Spec={specificity:.2f})", ha="left", va="center", fontsize=10)

    ax.set_title("Bayes Probability Tree: Structural Damage Test\n"
                 f"PPV = P(Damage|+) = {results['PPV']:.3f}, NPV = P(¬Damage|-) = {results['NPV']:.3f}")

    if save_path:
        fig.tight_layout()
        fig.savefig(save_path, dpi=200)
    plt.close(fig)


# -------------------------------
# Reporting
# -------------------------------

def create_statistical_report(output_file: Path,
                              concrete_stats: pd.DataFrame,
                              material_stats: pd.DataFrame,
                              fitted_params: Dict[str, float],
                              probability_results: Dict[str, float]) -> None:
    """
    Create a text report summarizing statistics, distribution fitting, and probabilities.
    """
    lines = []
    lines.append("Lab 4 Statistical Report\n")
    lines.append("== Concrete Strength: Descriptive Statistics ==\n")
    lines.append(concrete_stats.round(3).to_string(index=False))
    lines.append("\n\nEngineering Interpretation:")
    lines.append("- Mean & median indicate typical compressive strength for quality control.")
    lines.append("- Std, IQR quantify variability; higher values imply larger safety margins.")
    lines.append("- Skewness/kurtosis hint at tail risk: heavy right-tail may indicate rare high-strength batches.\n")

    lines.append("== Material Properties by Material Type ==\n")
    lines.append(material_stats.round(3).to_string())
    lines.append("\nInterpretation: Wider spread across a material implies greater uncertainty in design.")

    lines.append("\n\n== Fitted Normal to Concrete Strength ==\n")
    lines.append(f"μ (fit) = {fitted_params.get('mu'):0.3f}, σ (fit) = {fitted_params.get('sigma'):0.3f}")
    lines.append("Compare with sample mean/std to assess normality assumption.\n")

    lines.append("== Probability Scenarios ==\n")
    for k, v in probability_results.items():
        lines.append(f"{k}: {v:.6f}")

    lines.append("\nNotes for Civil Engineering Practice:")
    lines.append("- Binomial: batch defect counts; use for acceptance sampling.")
    lines.append("- Poisson: event counts per hour (e.g., heavy trucks).")
    lines.append("- Normal: strengths & loads; percentile checks for design thresholds.")
    lines.append("- Exponential: time-to-failure; useful for maintenance planning.\n")

    output_file.write_text("\n".join(lines), encoding="utf-8")


def write_summary_md(output_file: Path,
                     concrete_stats: pd.DataFrame,
                     per_material: pd.DataFrame,
                     probability_results: Dict[str, float],
                     generated_plots: Dict[str, str]) -> None:
    """
    Create a concise markdown summary.
    """
    md = []
    md.append("# Lab 4 Summary")
    md.append("## Key Statistics (Concrete)")
    md.append(concrete_stats.round(3).to_string(index=False))
    md.append("\n## Key Statistics by Material Type")
    md.append(per_material.round(3).to_string())
    md.append("\n## Probability Results")
    for k, v in probability_results.items():
        md.append(f"- **{k}**: {v:.6f}")
    md.append("\n## Generated Plots")
    for name, path in generated_plots.items():
        md.append(f"- **{name}** → `{path}`")
    md.append("\n## Engineering Interpretations")
    md.append("- Higher variability (std, IQR) suggests conservative design choices.")
    md.append("- Percentiles help set acceptance criteria (e.g., 5th/95th for strengths/loads).")
    md.append("- PPV/NPV guide decisions after diagnostic tests (repair vs. monitor).")

    output_file.write_text("\n".join(md), encoding="utf-8")


# -------------------------------
# Main Workflow
# -------------------------------

def main() -> None:
    parser = argparse.ArgumentParser(description="Lab 4 Statistical Analysis")
    parser.add_argument("--concrete_csv", default="concrete_strength.csv",
                        help="Concrete strength CSV filename or path")
    parser.add_argument("--loads_csv", default="structural_loads.csv",
                        help="Structural loads CSV filename or path")
    parser.add_argument("--materials_csv", default="material_properties.csv",
                        help="Material properties CSV filename or path")
    parser.add_argument("--outdir", default=".",
                        help="Output directory (default: current script folder)")
    args = parser.parse_args()

    # Resolve output directory
    outdir = Path(args.outdir).resolve()
    outdir.mkdir(parents=True, exist_ok=True)

    # Load datasets
    concrete = load_data(args.concrete_csv)
    loads = load_data(args.loads_csv)
    materials = load_data(args.materials_csv)

    # Basic exploration printouts
    print("=== Data Exploration ===")
    for name, df in [("Concrete", concrete), ("Loads", loads), ("Materials", materials)]:
        print(f"\n-- {name} --")
        print("Shape:", df.shape)
        print("Columns:", list(df.columns))
        print(df.dtypes)
        print("Head:\n", df.head(5).to_string(index=False))

    # Handle simple missing values (drop rows with NA in numeric columns for core analyses)
    # (Alternative strategies could be used; for synthetic data this is sufficient.)
    for df in [concrete, loads, materials]:
        for c in df.columns:
            if pd.api.types.is_numeric_dtype(df[c]):
                # Keep NAs if any for transparency but drop when computing stats
                pass

    # Part 1: Descriptive stats for concrete strengths
    concrete_col = "strength_mpa"
    concrete_stats = calculate_descriptive_stats(concrete, column=concrete_col)
    print("\n=== Descriptive Statistics: Concrete Strength (MPa) ===")
    print(concrete_stats.round(3).to_string(index=False))

    # Visualization: histogram + KDE + mean/median/mode + sigma bands
    concrete_hist_path = outdir / "concrete_strength_distribution.png"
    plot_distribution(concrete, concrete_col,
                      title="Concrete Strength Distribution",
                      save_path=concrete_hist_path)

    # Shape measures are included in the stats above; also add boxplot
    # (Part 1: Quantiles & boxplot)
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.boxplot(concrete[concrete_col].dropna().values, showmeans=True)
    ax.set_title("Concrete Strength: Boxplot")
    ax.set_ylabel("strength_mpa")
    ax.grid(True, linestyle=":")
    boxplot_path = outdir / "concrete_strength_boxplot.png"
    fig.tight_layout(); fig.savefig(boxplot_path, dpi=200); plt.close(fig)

    # Part 2: Probability distributions & fitting
    # Fit normal to concrete strengths
    fitted_params = fit_distribution(concrete, column=concrete_col, distribution_type="normal")
    dist_fit_path = outdir / "distribution_fitting.png"
    plot_distribution_fitting(concrete, concrete_col, fitted_params, save_path=dist_fit_path)

    # Create probability distributions overview figure
    prob_fig_path = outdir / "probability_distributions.png"
    plot_probability_distributions(save_path=prob_fig_path)

    # Part 3: Probability scenarios
    # Binomial: n=100, p=0.05
    binom_p_exact3 = calculate_probability_binomial(n=100, p=0.05, k=3)
    binom_p_le5 = calculate_probability_binomial_cdf(n=100, p=0.05, k=5)

    # Poisson: λ=10
    pois_p_eq8 = calculate_probability_poisson(lmbda=10, k=8)
    pois_p_gt15 = calculate_probability_poisson_sf(lmbda=10, k=15)

    # Normal: mean=250, std=15
    norm_p_gt280 = calculate_probability_normal(mean=250, std=15, x_lower=280, x_upper=None)
    norm_p_95th = stats.norm.ppf(0.95, loc=250, scale=15)

    # Exponential: mean=1000 hours
    exp_p_fail_before_500 = calculate_probability_exponential(mean=1000, x=500, tail="le")
    exp_p_survive_beyond_1500 = calculate_probability_exponential(mean=1000, x=1500, tail="gt")

    # Bayes theorem scenario
    prior, sensitivity, specificity = 0.05, 0.95, 0.90
    bayes_results = apply_bayes_theorem(prior, sensitivity, specificity)

    # Collect probability outputs
    probability_results = {
        "Binomial P(X=3) [n=100,p=0.05]": binom_p_exact3,
        "Binomial P(X<=5) [n=100,p=0.05]": binom_p_le5,
        "Poisson P(X=8) [λ=10]": pois_p_eq8,
        "Poisson P(X>15) [λ=10]": pois_p_gt15,
        "Normal P(X>280) [μ=250,σ=15]": norm_p_gt280,
        "Normal 95th percentile [μ=250,σ=15]": float(norm_p_95th),
        "Exponential P(T<=500) [mean=1000]": exp_p_fail_before_500,
        "Exponential P(T>1500) [mean=1000]": exp_p_survive_beyond_1500,
        "Bayes PPV P(Damage|+)": bayes_results["PPV"],
        "Bayes NPV P(¬Damage|-)": bayes_results["NPV"],
    }

    # Visualize Bayes probability tree
    bayes_tree_path = outdir / "bayes_probability_tree.png"
    plot_bayes_probability_tree(prior, sensitivity, specificity, save_path=bayes_tree_path)

    # Part 3: Basic comparison across materials (boxplot)
    mat_col = "yield_strength_mpa"
    mat_group = "material_type"
    material_box_path = outdir / "material_comparison_boxplot.png"
    plot_material_comparison(materials, column=mat_col, group_column=mat_group,
                             save_path=material_box_path)

    # Per-material summary stats
    per_material = (
        materials.groupby(mat_group)[mat_col]
        .agg(["count", "mean", "std", "min", "median", "max", "var"])
        .rename(columns={"median": "q2_median", "var": "variance"})
    )
    print("\n=== Material Yield Strength by Type ===")
    print(per_material.round(3).to_string())

    # Structural loads: simple dashboard (time series & histogram)
    # We keep it simple due to lab focus
    fig, ax = plt.subplots(figsize=(8, 4))
    # Ensure timestamp is parsed
    loads_plot = loads.copy()
    if "timestamp" in loads_plot.columns:
        try:
            loads_plot["timestamp"] = pd.to_datetime(loads_plot["timestamp"])
            loads_plot = loads_plot.sort_values("timestamp")
            ax.plot(loads_plot["timestamp"], loads_plot["load_kN"])
            ax.set_title("Structural Loads Over Time")
            ax.set_xlabel("Time"); ax.set_ylabel("load_kN")
            ax.grid(True, linestyle=":")
            summary_dash_path = outdir / "statistical_summary_dashboard.png"
            fig.tight_layout(); fig.savefig(summary_dash_path, dpi=200)
        except Exception:
            pass
    plt.close(fig)

    # Create text report
    report_path = outdir / "lab4_statistical_report.txt"
    create_statistical_report(output_file=report_path,
                              concrete_stats=concrete_stats,
                              material_stats=per_material,
                              fitted_params=fitted_params,
                              probability_results=probability_results)

    # Create concise summary md
    summary_md_path = outdir / "lab4_summary.md"
    generated_plots = {
        "Concrete Strength Distribution": str(concrete_hist_path.name),
        "Concrete Strength Boxplot": str(boxplot_path.name),
        "Distribution Fitting": str(dist_fit_path.name),
        "Probability Distributions": str(prob_fig_path.name),
        "Bayes Probability Tree": str(bayes_tree_path.name),
        "Material Comparison Boxplot": str(material_box_path.name),
        "Statistical Summary Dashboard": "statistical_summary_dashboard.png",
    }
    write_summary_md(output_file=summary_md_path,
                     concrete_stats=concrete_stats,
                     per_material=per_material,
                     probability_results=probability_results,
                     generated_plots=generated_plots)

    # Console outputs for grading
    print("\n=== Fitted Normal (Concrete Strength) ===")
    print(f"mu={fitted_params.get('mu'):.4f}, sigma={fitted_params.get('sigma'):.4f}")

    print("\n=== Probability Results ===")
    for k, v in probability_results.items():
        print(f"{k}: {v:.6f}")

    print(f"\nGenerated report: {report_path}")
    print(f"Summary MD: {summary_md_path}")
    print("Generated plots:")
    for name, path in generated_plots.items():
        print(f" - {name}: {path}")


if __name__ == "__main__":
    main()
